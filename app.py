import os
from dotenv import load_dotenv
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from dotenv import load_dotenv
load_dotenv()  # â† .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, max_tokens=1000, api_key=os.getenv("OPENAI_API_KEY"))

st.title(" ç”ŸæˆAIå°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

st.write(
    """#####
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€2äººã®AIå°‚é–€å®¶ã«è³ªå•ã‚’æŠ•ã’ã‹ã‘ã€ç”ŸæˆAIã®æ´»ç”¨æ–¹æ³•ã«ã¤ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è³ªå•å†…å®¹ã«å¿œã˜ã¦ã€é©åˆ‡ãªå°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚
---
###### ğŸ”§ ä½¿ã„æ–¹
1. **å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠ**  
   - ã€ŒAIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ï¼šPythonã‚„LangChainã®ä½¿ã„æ–¹ã€RAGã‚„åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«é–¢ã™ã‚‹è³ªå•å‘ã‘  
   - ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ï¼šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ›¸ãæ–¹ã€æ¥­å‹™æ´»ç”¨ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹è¨­è¨ˆãªã©ã®ç›¸è«‡å‘ã‘  
2. **è³ªå•ã‚’å…¥åŠ›**  
   - ãƒ•ã‚©ãƒ¼ãƒ ã«è‡ªç”±ãªè³ªå•æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€ŒRAGã£ã¦ä½•ã§ã™ã‹ï¼Ÿã€ï¼‰
3. **å›ç­”ã‚’ç¢ºèª**  
   - æ•°ç§’å¾Œã«ã€å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”ãŒç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
---
###### ğŸ’¬ ã”åˆ©ç”¨ä¾‹
- ã€ŒRAGã‚·ã‚¹ãƒ†ãƒ ã‚’Streamlitã§å‹•ã‹ã™ã«ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿã€
- ã€Œå–¶æ¥­æ”¯æ´ã«å‘ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ ã‚’æ•™ãˆã¦ãã ã•ã„ã€
---
ğŸ“Œ *æœ¬ã‚¢ãƒ—ãƒªã¯å­¦ç¿’ç›®çš„ã§é–‹ç™ºã•ã‚ŒãŸã‚‚ã®ã§ã‚ã‚Šã€ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã¯å‚è€ƒæƒ…å ±ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚*
""")

selected_expert = st.radio("å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„",  ["AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"])

user_question = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹ï¼šå–¶æ¥­æ”¯æ´ã«å‘ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ ã‚’æ•™ãˆã¦ãã ã•ã„")

def get_expert_response(selected_expert, user_question):
    """radioãƒœã‚¿ãƒ³ã§é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã«å¿œã˜ã¦ã€é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™é–¢æ•°"""
    if selected_expert == "AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢":
        systemmessage = """You are an AI engineer specializing in Python and LangChain. 
                          You help users understand how to implement 
                          RAG (Retrieval-Augmented Generation) systems, 
                          use embedding vectors, and leverage other advanced techniques in AI development.
                          Please respond in Japanese."""
        
    else:
        systemmessage = """You are a prompt engineer and AI consultant who specializes in helping beginners design effective prompts and business use cases for generative AI. Your goal is to guide users in crafting prompts that achieve specific goals, such as automating tasks, retrieving relevant knowledge, or summarizing content. You are friendly and business-focused, and you always help clarify the purpose behind each prompt to ensure value-driven AI usage.
You provide practical examples and actionable advice to help users understand how to structure their prompts for maximum effectiveness. Always encourage users to think about the end goal of their prompts and how they can best achieve it with generative AI.
Please respond in Japanese."""
    
    messages = [
        SystemMessage(content=systemmessage),
        HumanMessage(content=user_question)
    ]
    return llm(messages)

if st.button("è³ªå•ã‚’é€ä¿¡"):
    if user_question:
        st.divider()
        try:
                result = get_expert_response(selected_expert, user_question)
                st.write(f"**{selected_expert}ã®å›ç­”ï¼š**")
                st.write(result.content)
        except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
