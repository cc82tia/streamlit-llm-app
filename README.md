# streamlit-llm-app
## 🛠️ Streamlit × LangChain による生成AI専門家アシスタント開発ログ

### 概要  
キャンプの課題にて、StreamlitとLangChain、OpenAI APIを組み合わせた対話型アプリを構築。  
ユーザーが「AIエンジニア」または「プロンプトエンジニア」を選択し、それぞれの専門家視点からの回答を受け取れる構成とした。

---

### 技術スタック  
- Python 3.11  
- Streamlit 1.41.1  
- LangChain（langchain-openai）  
- OpenAI GPT-4o-mini  
- python-dotenv  
- Git / GitHub / Streamlit Community Cloud  

---

### 実装の主なポイント

- LangChainの`SystemMessage`によって、LLMに異なる専門家役割（AIエンジニア／プロンプトエンジニア）を割り当てる構成を設計。
- Streamlit UIではラジオボタンと入力フォームを用意し、質問に応じて応答が返される構成を実装。
- `.env`ファイルによるAPIキーの安全な管理と、`.gitignore`によるGit非公開設定を明確に理解。
- OpenAI APIへの呼び出しを明示的に行う形で、実装エラーのトラブルを解決。

---

### 試行錯誤と学び

#### 1. APIキー読み込みの順序エラー  
`load_dotenv()`より前に`ChatOpenAI()`を呼び出してしまい、APIキーが読み込まれずエラーに。  
→ 実行順の重要性と、環境変数の取り扱いへの理解が深まった。

#### 2. Streamlit UI関数の仕様誤解  
`st.divider("テキスト")`と記述しエラー。引数を取らない関数であることを思いつきもしなかった。  
→ 公式ドキュメントを確認する習慣の重要性を再認識。

#### 3. VSCode上のモジュール警告  
PylanceがLangChainの構成を解決できずエラー表示。仮想環境の選択やモジュール構成の変更で対応。  
→ 仮想環境とエディタ連携、ライブラリの進化への追従が必要であることを体感。

---

### 最終成果物の機能

- 専門家（AIエンジニア／プロンプトエンジニア）選択によるLLM応答切替
- ユーザー入力→LangChain→OpenAI API→Streamlit UI という一連の処理構成
- ローカルおよびStreamlit Community Cloudにて正常動作
- `.env`によるセキュアな環境変数管理

---

### 成長実感

- 環境構築（venv、.env、.gitignoreなど）からコード設計、デプロイまでを一貫して自分で完了できた。
- エラー発生時に「何が問題か」「どう直すか」を冷静に判断し、言語化して記録できるようになってきた。
- コードだけでなく、「構成・順序・セキュリティ・ドキュメント」の全体像が見え始めた。

---

### 今後の展望と改善ポイント

- `st.chat_message()`によるチャットUIへの拡張
- `st.session_state`での履歴保持による多ターン対話への対応
- OpenAIのストリーミング機能（stream=True）による応答速度改善
- 複数の専門家をToolとして分離したLangChainエージェント構成への発展

---

### 公開にあたって  
この記録は、学習と実装を通して得た理解・発見・反省を振り返るためのものであり、将来的に自走力を高めるための基礎資料とすることを目的としています。  
同じ学習過程を進む方の参考になれば幸いです。
